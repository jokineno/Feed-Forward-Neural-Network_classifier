{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from plotting import plot_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- hyperparameters ---\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_TEST = 100\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0e1dc9e40547289e6072c2867fc7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# --- CIFAR initialization ---\n",
    "\n",
    "# We transform torchvision.datasets.CIFAR10 outputs to tensors\n",
    "# Plus, we add a random horizontal transformation to the training data\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=train_transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Create Pytorch data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    print(\"img\",img)\n",
    "    img = img / 2 + 0.5\n",
    "    print(\"img2\", img)\n",
    "    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 32, 32])\n",
      "tensor([2, 7, 7, 3, 9, 1, 8, 4, 4, 8, 6, 3, 7, 5, 7, 3, 3, 9, 5, 6, 9, 4, 4, 2,\n",
      "        6, 5, 1, 9, 6, 3, 8, 2, 1, 5, 4, 3, 3, 3, 5, 3, 8, 0, 6, 8, 0, 4, 6, 2,\n",
      "        5, 4, 5, 6, 3, 5, 5, 8, 0, 2, 0, 3, 0, 2, 5, 4, 8, 3, 1, 7, 8, 3, 6, 2,\n",
      "        5, 4, 0, 2, 8, 5, 7, 2, 3, 5, 6, 9, 1, 2, 5, 4, 6, 5, 6, 0, 0, 3, 5, 0,\n",
      "        9, 9, 3, 5])\n",
      "img tensor([[[0.7725, 0.7804, 0.7765,  ..., 0.7333, 0.7333, 0.7490],\n",
      "         [0.7804, 0.7882, 0.7843,  ..., 0.7490, 0.7451, 0.7608],\n",
      "         [0.7765, 0.7804, 0.7804,  ..., 0.7490, 0.7451, 0.7608],\n",
      "         ...,\n",
      "         [0.7882, 0.7882, 0.7647,  ..., 0.7686, 0.7686, 0.7216],\n",
      "         [0.7843, 0.7804, 0.7569,  ..., 0.7647, 0.7686, 0.7804],\n",
      "         [0.7843, 0.7725, 0.7451,  ..., 0.7412, 0.7373, 0.7569]],\n",
      "\n",
      "        [[0.7176, 0.7255, 0.7216,  ..., 0.6745, 0.6745, 0.6902],\n",
      "         [0.7255, 0.7333, 0.7294,  ..., 0.6902, 0.6863, 0.6980],\n",
      "         [0.7216, 0.7255, 0.7255,  ..., 0.6902, 0.6863, 0.7020],\n",
      "         ...,\n",
      "         [0.7216, 0.7216, 0.6980,  ..., 0.7098, 0.7137, 0.6627],\n",
      "         [0.7176, 0.7137, 0.6902,  ..., 0.7098, 0.7137, 0.7255],\n",
      "         [0.7176, 0.7059, 0.6824,  ..., 0.6902, 0.6863, 0.7020]],\n",
      "\n",
      "        [[0.6039, 0.6118, 0.6078,  ..., 0.5647, 0.5647, 0.5765],\n",
      "         [0.6118, 0.6196, 0.6157,  ..., 0.5725, 0.5725, 0.5843],\n",
      "         [0.6078, 0.6118, 0.6078,  ..., 0.5765, 0.5725, 0.5843],\n",
      "         ...,\n",
      "         [0.6118, 0.6118, 0.5882,  ..., 0.5765, 0.5804, 0.5255],\n",
      "         [0.6078, 0.6039, 0.5804,  ..., 0.5725, 0.5765, 0.5843],\n",
      "         [0.5961, 0.5922, 0.5725,  ..., 0.5647, 0.5608, 0.5765]]])\n",
      "img2 tensor([[[0.8863, 0.8902, 0.8882,  ..., 0.8667, 0.8667, 0.8745],\n",
      "         [0.8902, 0.8941, 0.8922,  ..., 0.8745, 0.8725, 0.8804],\n",
      "         [0.8882, 0.8902, 0.8902,  ..., 0.8745, 0.8725, 0.8804],\n",
      "         ...,\n",
      "         [0.8941, 0.8941, 0.8824,  ..., 0.8843, 0.8843, 0.8608],\n",
      "         [0.8922, 0.8902, 0.8784,  ..., 0.8824, 0.8843, 0.8902],\n",
      "         [0.8922, 0.8863, 0.8725,  ..., 0.8706, 0.8686, 0.8784]],\n",
      "\n",
      "        [[0.8588, 0.8627, 0.8608,  ..., 0.8373, 0.8373, 0.8451],\n",
      "         [0.8627, 0.8667, 0.8647,  ..., 0.8451, 0.8431, 0.8490],\n",
      "         [0.8608, 0.8627, 0.8627,  ..., 0.8451, 0.8431, 0.8510],\n",
      "         ...,\n",
      "         [0.8608, 0.8608, 0.8490,  ..., 0.8549, 0.8569, 0.8314],\n",
      "         [0.8588, 0.8569, 0.8451,  ..., 0.8549, 0.8569, 0.8627],\n",
      "         [0.8588, 0.8529, 0.8412,  ..., 0.8451, 0.8431, 0.8510]],\n",
      "\n",
      "        [[0.8020, 0.8059, 0.8039,  ..., 0.7824, 0.7824, 0.7882],\n",
      "         [0.8059, 0.8098, 0.8078,  ..., 0.7863, 0.7863, 0.7922],\n",
      "         [0.8039, 0.8059, 0.8039,  ..., 0.7882, 0.7863, 0.7922],\n",
      "         ...,\n",
      "         [0.8059, 0.8059, 0.7941,  ..., 0.7882, 0.7902, 0.7627],\n",
      "         [0.8039, 0.8020, 0.7902,  ..., 0.7863, 0.7882, 0.7922],\n",
      "         [0.7980, 0.7961, 0.7863,  ..., 0.7824, 0.7804, 0.7882]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (i,j) in train_loader:\n",
    "    print(i.shape) # 100 x 3 x 32 x 32\n",
    "    print(j)\n",
    "    kuva = i[0]\n",
    "    imshow(kuva)\n",
    "    break\n",
    "    \n",
    "# data is ok! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing CNN \n",
    "\n",
    "- The input:  BATCH SIZE TRAIN x NUM CHANNELS x WIDTH x HEIGHT,\n",
    "    - where NUM CHANNELS=3 (R-G-B channels), and WIDTH=HEIGHT=32 (pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please make sure your model includes at least two convolutional layers, followed by suitable non- linear functions and max pooling layers. Since there will be a rather large number of layers, please consider also to organize these layers into an torch.nn.Sequential module, which may result in cleaner code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- model ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNN, self).__init__()\n",
    "        # WRITE CODE HERE\n",
    "        \n",
    "        # convolution 1 \n",
    "        #non linear: relu, tanh, sigmoid\n",
    "        # max pooling\n",
    "        \n",
    "        # convolution 2\n",
    "        #non linear\n",
    "        #max pooling\n",
    "        \n",
    "        #esimerkiss√§ input kuvat on 28*28\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # WRITE CODE HERE\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8f6829121f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# WRITE CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "#--- set up ---\n",
    "if __name__=='__main__':\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model = CNN().to(device)\n",
    "\n",
    "    # WRITE CODE HERE\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    #--- training ---\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        total = 0\n",
    "        for batch_num, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # WRITE CODE HERE\n",
    "            print(\"batch_num:\" batch_num)\n",
    "            print(\"\\n \\n\")\n",
    "            print(\"Data:\", data)\n",
    "            print(\"\\n \\n\")\n",
    "            print(\"target:\",target)\n",
    "            print(\"\\n \\n\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            break\n",
    "            loss = loss_function(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss\n",
    "            total += BATCH_SIZE_TRAIN\n",
    "\n",
    "            print('Epoch %d - Batch %d/%d: Loss: %.4f | Train Acc: %.3f%% (%d/%d)' % (epoch, batch_num, len(train_loader), train_loss / (batch_num + 1), 100. * train_correct / total, train_correct, total))\n",
    "    break\n",
    "\n",
    "    #--- test ---\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # WRITE CODE HERE\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "            print('Evaluating: Batch %d/%d: Loss: %.4f | Test Acc: %.3f%% (%d/%d)' % (batch_num, len(test_loader), test_loss / (batch_num + 1), 100. * test_correct / total, test_correct, total))\n",
    "            \n",
    "\n",
    "    # WRITE CODE HERE\n",
    "    #visualize weights for the first conv layer\n",
    "    conv_layer = None\n",
    "    plot_weights(conv_layer.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
